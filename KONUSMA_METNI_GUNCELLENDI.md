# SUNUM KONUÅMA METNÄ° - GÃœNCELLENMIÅ VERSÄ°YON

## âš ï¸ KRÄ°TÄ°K NOTLAR (SUNUMDAN Ã–NCE OKU!)

**GERÃ‡EK DEÄERLER (Koddan alÄ±ndÄ±):**
```
Dataset: 3,761 sample
  - Train: 2,632 (70%)
  - Val: 376 (10%)
  - Test: 753 (20%)

EN Ä°YÄ° MODEL: Linear SVM â­
  - Test F1: 96.18%
  - Test Acc: 96.15%
  - CV F1: 95.99% Â± 0.19%
  - Training Time: 0.32s
  - MCC: 0.9427

DÄ°ÄER MODELLER:
  - MLP (Deep Learning): 95.54% F1, 3.44s
  - Logistic Regression: 93.84% F1, 1.57s
  - Random Forest: 91.15% F1, 0.08s

FEATURES:
  - TF-IDF: 1000 (n-gram 1-3)
  - BoW: 500 (n-gram 1-2)
  - Word2Vec: 100
  - Custom: 14
  - Combined: 1014

HATALAR:
  - Total: 29/753 (3.85%)
  - Negative: 9/242 (3.7%)
  - Neutral: 6/248 (2.4%)
  - Positive: 14/263 (5.3%)
```

---

## ZAMANLAMA (~15 dakika)

| KiÅŸi | BÃ¶lÃ¼m | SÃ¼re |
|------|-------|------|
| **MEHMET TAHA** | GiriÅŸ + Problem + Veri + Features | **7 dk** |
| **MERVE** | Modeller + SonuÃ§lar | **5 dk** |
| **ELIF** | GÃ¶rseller + SonuÃ§ | **3 dk** |

---

# BÃ–LÃœM 1: MEHMET TAHA (7 dakika)

---

## SLAYT 1: KAPAK (30 sn)

**[KONUÅMA]**
> "Ä°yi gÃ¼nler hocam. Ben Mehmet Taha BoynikoÄŸlu, Financial Sentiment Analysis projemizi sunacaÄŸÄ±z."
>
> "Ekip arkadaÅŸlarÄ±m Merve Kedersiz ve Elif Hande Arslan."
>
> "Ben veri toplama ve feature engineering'i anlatacaÄŸÄ±m. Merve modelleri, Elif sonuÃ§larÄ± Ã¶zetleyecek."

---

## SLAYT 2: PROBLEM TANIMI (1.5 dk)

**[KONUÅMA]**
> "Problemimiz ÅŸu: Finansal piyasalarda her gÃ¼n binlerce haber yayÄ±nlanÄ±yor. Bloomberg, Reuters, Yahoo Finance... Bir yatÄ±rÄ±mcÄ± bunlarÄ± manuel okuyamaz."
>
> "Ã‡Ã¶zÃ¼mÃ¼mÃ¼z **Sentiment Analysis** - duygu analizi. Bir haberin olumlu mu, olumsuz mu, yoksa nÃ¶tr mÃ¼ olduÄŸunu otomatik tespit ediyoruz."
>
> "**Ã–rnek:** 'Stock prices surged' pozitif, 'Company faces losses' negatif, 'Market remained unchanged' nÃ¶tr."
>
> "Projemizde **Linear SVM modeli ile %96.18 F1-Score** elde ettik. Yani 100 haberden 96'sÄ±nÄ± doÄŸru sÄ±nÄ±flandÄ±rÄ±yoruz."

---

## SLAYT 3: VERÄ° TOPLAMA (2 dk)

**[TERMÄ°NAL DEMO GÃ–STERÄ°RKEN]**

> "Veri toplama sÃ¼recini gÃ¶stereyim."

```bash
python3 create_full_dataset.py
```

**[Ã‡IKTIYI GÃ–STERÄ°RKEN]**
```
[STEP 1] Loading REAL scraped financial news...
  Loaded 451 real news articles from RSS feeds
  Real data distribution:
    Negative: 72 (16.0%)
    Neutral: 220 (48.8%)
    Positive: 159 (35.3%)

[STEP 2] Adding template-based samples for balance...
  Added 1199 template samples

[STEP 3] Combining real + template data...
  Combined dataset: 1650 samples
  Distribution before augmentation:
    Negative: 550 (33.3%)
    Neutral: 550 (33.3%)
    Positive: 550 (33.3%)

[STEP 4] Applying data augmentation...
  Augmented dataset: 3761 samples

[STEP 5] Creating train/validation/test splits...
  Training set:   2632 samples (70.0%)
  Validation set: 376 samples (10.0%)
  Test set:       753 samples (20.0%)
```

**[KONUÅMA]**
> "**AdÄ±m 1:** 451 gerÃ§ek RSS haberi topladÄ±k (Yahoo Finance, CNBC, MarketWatch)."
>
> "Ama problemi gÃ¶rÃ¼yorsunuz - **class imbalance**: Neutral %48, Positive %35, Negative sadece %16."
>
> "**Neden sorun?** Model Ã§ok gÃ¶rdÃ¼ÄŸÃ¼ sÄ±nÄ±fÄ± iyi Ã¶ÄŸrenir, az gÃ¶rdÃ¼ÄŸÃ¼nÃ¼ ihmal eder."
>
> "**AdÄ±m 2:** Template Ã¶rnekler ekledik - her sÄ±nÄ±fÄ± 550'ye tamamladÄ±k. ArtÄ±k dengelendi."
>
> "**AdÄ±m 3:** Data augmentation - synonym replacement, random swap. 1650'den 3761'e Ã§Ä±kardÄ±k."
>
> "**Proje gereksinimi 2000+ idi, biz 3761 topladÄ±k - %88 fazla!**"
>
> "**AdÄ±m 4:** Train/Val/Test: 70/10/20 bÃ¶ldÃ¼k. **Test 753 sample - gereksinim 500+ idi, %50 fazla verdik!**"

---

## SLAYT 4: FEATURE ENGINEERING (2.5 dk)

**[KONUÅMA]**
> "Åimdi en Ã¶nemli kÄ±sÄ±m: **Feature Engineering**."
>
> "**Problem:** Bilgisayar 'Apple stock surged' cÃ¼mlesini anlayamaz. CPU sadece sayÄ± iÅŸler."
>
> "**Ã‡Ã¶zÃ¼m:** CÃ¼mleyi sayÄ±lara Ã§eviriyoruz. Buna **vektÃ¶r** diyoruz."
>
> "**4 farklÄ± yÃ¶ntem kullandÄ±k** - proje gereksinimi:"

> "**1. TF-IDF (2632, 1000):**"
> "Her cÃ¼mle 1000 sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼."
>
> "**TF-IDF nedir?** Term Frequency Ã— Inverse Document Frequency."
> "- TF: Kelime cÃ¼mlede kaÃ§ kez geÃ§iyor"
> "- IDF: Kelime tÃ¼m cÃ¼mlelerde ne kadar nadir"
> "- Nadir ama Ã¶nemli kelimeler yÃ¼ksek skor alÄ±r"
>
> "Ã–rnek: 'the' her yerde var â†’ dÃ¼ÅŸÃ¼k skor. 'surged' nadir ve Ã¶nemli â†’ yÃ¼ksek skor."
>
> "**Neden 1000?** Binlerce kelime var ama en Ã¶nemli 1000'ini seÃ§tik. FazlasÄ± gÃ¼rÃ¼ltÃ¼."

> "**2. Bag-of-Words (2632, 500):**"
> "BasitÃ§e kelime sayÄ±mÄ±. 'profit profit loss' â†’ profit:2, loss:1"
>
> "**Bigram'lar da var** - 'strong growth' gibi 2 kelimelik ifadeler."

> "**3. Word2Vec (2632, 100):**"
> "Kelimelerin anlamÄ±nÄ± yakalayan vektÃ¶r."
> "'profit' ve 'earnings' yakÄ±n vektÃ¶rler Ã§Ã¼nkÃ¼ anlamlarÄ± benzer."

> "**4. Custom Features (2632, 14):**"
> "Finansal domain'e Ã¶zel Ã¶zellikler:"
> "- positive_count: KaÃ§ pozitif kelime var (surge, profit)"
> "- negative_count: KaÃ§ negatif kelime var (crash, loss)"
> "- sentiment_score: positive - negative"
> "- ticker_count: $AAPL, $TSLA gibi hisse sembolleri"
>
> "**14 tane finansal Ã¶zellik tanÄ±mladÄ±k** - domain bilgisi ekliyoruz."

> "**SonuÃ§: (2632, 1014)** - TF-IDF (1000) + Custom (14) birleÅŸtirdik."
> "Her cÃ¼mle 1014 sayÄ± ile temsil ediliyor."

---

# BÃ–LÃœM 2: MERVE (5 dakika)

---

## SLAYT 5: MODELLER (2 dk)

**[KONUÅMA]**
> "Ben Merve, modelleri anlatacaÄŸÄ±m."
>
> "**4 model eÄŸittik** - proje 2 traditional ML + 1 deep learning istiyor, biz 3+1 yaptÄ±k:"

> "**1. Logistic Regression:** En basit lineer model. L2 regularization ile overfitting Ã¶nlÃ¼yoruz."
>
> "**2. Linear SVM:** Support Vector Machine. En iyi ayÄ±rÄ±cÄ± Ã§izgiyi buluyor - iki sÄ±nÄ±f arasÄ±ndaki boÅŸluÄŸu maksimize ediyor."
>
> "**3. Random Forest:** 100 karar aÄŸacÄ± oluÅŸturup oylama yapÄ±yor. Ensemble learning."
>
> "**4. MLP (Deep Learning):** Multi-Layer Perceptron. **3 hidden layer: 256 â†’ 128 â†’ 64 nÃ¶ron.** ReLU activation, early stopping ile overfitting Ã¶nlÃ¼yoruz."

> "**Overfitting Ã¶nleme iÃ§in 3 teknik:**"
> "- **L2 Regularization:** BÃ¼yÃ¼k aÄŸÄ±rlÄ±klarÄ± cezalandÄ±rÄ±yor (LogReg, SVM, MLP)"
> "- **Early Stopping:** Validation kÃ¶tÃ¼leÅŸtiÄŸinde durduruyor (MLP)"
> "- **5-Fold CV:** 5 farklÄ± bÃ¶lÃ¼mle test - daha gÃ¼venilir skor"

---

## SLAYT 6: SONUÃ‡LAR (3 dk)

**[TERMÄ°NAL Ã‡IKTISINI GÃ–STERÄ°RKEN]**

```
Model                     CV F1                Test F1    Test Acc   MCC        Time      
------------------------------------------------------------------------------------------
Linear SVM                0.9599 Â± 0.0019   0.9618     0.9615     0.9427     0.32s  â­
MLP (Deep Learning)       0.9582 Â± 0.0070   0.9554     0.9548     0.9330     3.44s
Logistic Regression       0.9327 Â± 0.0077   0.9384     0.9376     0.9083     1.57s
Random Forest             0.9146 Â± 0.0116   0.9115     0.9097     0.8698     0.08s
```

**[KONUÅMA]**
> "SonuÃ§lar tablosu burada."
>
> "**Linear SVM %96.18 F1-Score ile en iyi!** Hem en yÃ¼ksek skor hem de Ã§ok hÄ±zlÄ± - 0.32 saniye."
>
> "**Neden SVM kazandÄ±?**"
> "1. **TF-IDF + SVM klasik gÃ¼Ã§lÃ¼ kombinasyon** - sparse features iÃ§in ideal"
> "2. **HÄ±z:** 0.32s vs 3.44s (MLP 10x daha yavaÅŸ)"
> "3. **Finansal sentiment keyword-based** - 'profit' gÃ¶rÃ¼rsen pozitif, 'loss' gÃ¶rÃ¼rsen negatif. Lineer ayÄ±rma yeterli."
>
> "**MLP ikinci sÄ±rada %95.54** - yine de Ã§ok baÅŸarÄ±lÄ±! Ama deep learning iÃ§in dataset biraz kÃ¼Ã§Ã¼k (ideal 10K+)."

> "**F1-Score nedir?** Precision ve Recall'Ä±n harmonik ortalamasÄ±."
> "- Precision: Pozitif dediklerimin kaÃ§Ä± gerÃ§ekten pozitif?"
> "- Recall: GerÃ§ek pozitiflerin kaÃ§Ä±nÄ± yakaladÄ±m?"
> "- Dengesiz verilerde accuracy'den daha gÃ¼venilir."
>
> "**MCC 0.9427** - Matthews Correlation Coefficient. -1 ile +1 arasÄ±, 1 = mÃ¼kemmel. **0.94 modelin gerÃ§ekten Ã¶ÄŸrendiÄŸini gÃ¶steriyor, ÅŸans deÄŸil.**"

> "**CV vs Test Scores:**"
> "- CV: 95.99% Â± 0.19%"
> "- Test: 96.18%"
> "- **Test > CV = Ä°yi generalization!** Overfitting olsa test dÃ¼ÅŸÃ¼k olurdu."

---

# BÃ–LÃœM 3: ELIF (3 dakika)

---

## SLAYT 7: CONFUSION MATRIX (1 dk)

**[FÄ°GURES/CONFUSION_MATRICES.PNG GÃ–STERÄ°RKEN]**

**[KONUÅMA]**
> "Ben Elif, gÃ¶rselleri Ã¶zetleyeceÄŸim."
>
> "**Confusion Matrix:** GerÃ§ek sÄ±nÄ±f vs tahmin edilen sÄ±nÄ±f tablosu."

```
          Pred Neg  Pred Neu  Pred Pos
True Neg       233         8         1      (242 total)
True Neu         3       242         3      (248 total)
True Pos         0        14       249      (263 total)
```

> "**Diagonal = DoÄŸru tahminler:** 233+242+249 = 724 doÄŸru"
> "**Off-diagonal = Hatalar:** Toplam 29 hata"
>
> "**En Ã§ok hata nerede?** Positive â†’ Neutral (14 hata). Neden? Mixed sentiment - hem pozitif hem nÃ¶tr kelimeler var."

---

## SLAYT 8: LEARNING CURVES & ROC (1 dk)

**[FIGURES/LEARNING_CURVES.PNG GÃ–STERÄ°RKEN]**

**[KONUÅMA]**
> "**Learning Curves:** Mavi training, turuncu CV."
> "**Ä°kisi yakÄ±n â†’ overfitting yok!** Ezberleme olsa mavi Ã§ok yÃ¼ksek, turuncu dÃ¼ÅŸÃ¼k olurdu."

**[FIGURES/ROC_CURVES.PNG GÃ–STERÄ°RKEN]**

> "**ROC Curves:** True Positive Rate vs False Positive Rate."
> "**AUC (egri altÄ±ndaki alan) hepsi 0.99+** - mÃ¼kemmel sÄ±nÄ±f ayrÄ±mÄ±!"

---

## SLAYT 9: PROJE GEREKSÄ°NÄ°MLERÄ° (1 dk)

**[KONUÅMA]**
> "**TÃ¼m proje gereksinimlerini karÅŸÄ±ladÄ±k:**"
>
> "âœ… **3761 sample** (gereksinim 2000+) - %88 fazla"
> "âœ… **753 test** (gereksinim 500+) - %50 fazla"
> "âœ… **451 gerÃ§ek RSS haberi** - gerÃ§ek web scraping"
> "âœ… **3 Traditional ML + 1 Deep Learning** - gereksinim karÅŸÄ±landÄ±"
> "âœ… **4 feature tipi** - BoW, TF-IDF, Word2Vec, Custom"
> "âœ… **5-Fold CV** - gÃ¼venilir skor"
> "âœ… **L2 + Early Stopping** - overfitting Ã¶nleme"

> "**SonuÃ§: Linear SVM - 96.18% F1-Score**"
> "753 testten sadece 29 hata - %3.85 hata oranÄ±!"
>
> "TeÅŸekkÃ¼rler! SorularÄ±nÄ±zÄ± alabiliriz."

---

# SORU-CEVAP HAZIRLIGI

## S: "Neden MLP en iyi deÄŸil? Deep learning daha iyi olmalÄ±?"

**C:**
> "HaklÄ±sÄ±nÄ±z hocam, teoride deep learning daha iyi olmalÄ±. Ancak 3 sebepten SVM kazandÄ±:"
> 
> "1. **Dataset size:** 3,761 sample MLP iÃ§in kÃ¼Ã§Ã¼k. Deep learning 10K+ data ile performans gÃ¶sterir."
> "2. **Feature type:** TF-IDF sparse features linear modeller iÃ§in optimal. Financial text keyword-based - complex patterns yok."
> "3. **Speed:** Production'da 0.32s kritik. MLP 3.44s sÃ¼rÃ¼yor."
> 
> "MLP yine de 95.54% aldÄ± - Ã§ok baÅŸarÄ±lÄ±! Future work'te FinBERT deneyebiliriz."

## S: "Word2Vec neden kullanmadÄ±nÄ±z?"

**C:**
> "Hocam, implement ettik (`word2vec_features.py`) ancak TF-IDF daha iyi sonuÃ§ verdi:"
> "- Financial sentiment keyword-based - 'surge' kelimesi her context'te pozitif"
> "- Word2Vec 3,761 sample ileì œëŒ€ë¡œ train olamadÄ±"
> "- Pre-trained Google News vectors financial domain'e spesifik deÄŸil"
> 
> "Future work: FinBERT veya domain-specific Word2Vec!"

## S: "451 haber yeterli mi?"

**C:**
> "451 gerÃ§ek RSS haberi + template + augmentation ile 3,761 sample oluÅŸturduk."
> "Proje gereksinimi 2,000 idi - %88 astÄ±k!"
> "Rule-based labeling ile quality saÄŸladÄ±k."
> "Future: Twitter API ile 10K+ sample toplayacaÄŸÄ±z."

## S: "Test > CV nasÄ±l olur? Overfitting yok mu?"

**C:**
> "Harika soru hocam! Test 96.18%, CV 95.99% - gap sadece +0.19%."
> "Bu **iyi generalization** gÃ¶steriyor:"
> "- Overfitting olsa test < CV olurdu"
> "- KÃ¼Ã§Ã¼k gap = model ezberlemiyor, genelliyor"
> "- L2 + Early Stopping + 5-Fold CV ile Ã¶nledik"

## S: "Confusion matrix'te en Ã§ok hata hangi sÄ±nÄ±fta?"

**C:**
> "Positive â†’ Neutral: 14 hata (5.3%)"
> "Sebep: Mixed sentiment - 'Stock rose but concerns remain' gibi cÃ¼mleler hem pozitif hem nÃ¶tr kelime iÃ§eriyor."
> "Future: Context-aware models (BERT) bu sorunu Ã§Ã¶zebilir."

---

# KOD-SUNUM EÅLEÅTIRMESI

## TERMÄ°NAL Ã‡IKTI â†’ SUNUM

| Sunum Ä°ddiasÄ± | Kod Ã‡Ä±ktÄ±sÄ± | Dosya | SatÄ±r |
|---------------|-------------|-------|-------|
| "3761 sample" | `Total: 3761 samples` | train_and_evaluate.py Ã§Ä±ktÄ± | - |
| "2632 train, 376 val, 753 test" | `Train: 2632, Val: 376, Test: 753` | train_and_evaluate.py Ã§Ä±ktÄ± | - |
| "TF-IDF 1000 feature" | `Shape: (2632, 1000)` | train_and_evaluate.py Ã§Ä±ktÄ± | - |
| "BoW 500 feature" | `Shape: (2632, 500)` | train_and_evaluate.py Ã§Ä±ktÄ± | - |
| "Word2Vec 100 feature" | `Shape: (2632, 100)` | train_and_evaluate.py Ã§Ä±ktÄ± | - |
| "Custom 14 feature" | `Shape: (2632, 14)` | train_and_evaluate.py Ã§Ä±ktÄ± | - |
| "Linear SVM 96.18%" | `Test F1: 0.9618` | train_and_evaluate.py Ã§Ä±ktÄ± | - |
| "MLP 95.54%" | `Test F1: 0.9554` | train_and_evaluate.py Ã§Ä±ktÄ± | - |
| "29 hata" | `Total errors: 29/753 (3.85%)` | train_and_evaluate.py Ã§Ä±ktÄ± | - |
| "MCC 0.9427" | `MCC: 0.9427` | train_and_evaluate.py Ã§Ä±ktÄ± | - |

## JUPYTER NOTEBOOK â†’ SUNUM

| Cell | Ä°Ã§erik | Sunumda Nerede KullanÄ±lÄ±r |
|------|--------|--------------------------|
| Cell 4 | Dataset stats | MEHMET TAHA - Veri toplama |
| Cell 5 | Distribution chart | MEHMET TAHA - Class balance |
| Cell 6 | Sample texts | MEHMET TAHA - GerÃ§ek Ã¶rnekler |
| Cell 11 | Model comparison table | MERVE - SonuÃ§lar |
| Cell 14 | Confusion matrix | ELIF - Hata analizi |
| Cell 16 | ROC curves | ELIF - Model ayrÄ±mÄ± |
| Cell 18 | Learning curves | ELIF - Overfitting kontrolÃ¼ |
| Cell 20 | Live prediction | DEMO - CanlÄ± tahmin |

---

## FÄ°NAL CHECKLIST (Sunumdan Ã¶nce)

- [ ] `python3 train_and_evaluate.py` Ã§alÄ±ÅŸtÄ±r - deÄŸerleri doÄŸrula
- [ ] `demo_notebook.ipynb` tÃ¼m cell'leri Ã§alÄ±ÅŸtÄ±r
- [ ] `figures/` klasÃ¶rÃ¼ndeki PNG'ler var mÄ± kontrol et
- [ ] KonuÅŸma metnindeki rakamlar kod Ã§Ä±ktÄ±sÄ±yla eÅŸleÅŸiyor mu?
- [ ] "Linear SVM en iyi" diyorsun, "MLP deÄŸil" diyorsun?

**HAZIR! BAÅARILAR! ğŸš€**
