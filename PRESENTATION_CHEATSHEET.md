# ğŸ“‹ PRESENTATION DAY CHEAT SHEET

## âœ… PRE-PRESENTATION CHECKLIST (5 min before)

```bash
# 1. Navigate to project
cd /Users/metaboy/Desktop/2121251034_MEHMET_TAHA_BOYNIKOGLU

# 2. Verify all files exist
ls data/processed/  # Should see train/val/test_clean.csv
ls models/          # Should see 4 .pkl files
ls figures/         # Should see confusion_matrices.png, roc_curves.png, etc.

# 3. Run verification (MUST PASS!)
python3 verify_presentation_alignment.py
# Expected: "âœ… ALL CHECKS PASSED"

# 4. Test imports
python3 -c "import numpy, pandas, sklearn, matplotlib; print('âœ… All libraries OK')"

# 5. Open demo notebook
jupyter notebook demo_notebook.ipynb
```

---

## ğŸ¯ KEY NUMBERS TO MEMORIZE

| Metric | Value | Where Used |
|--------|-------|------------|
| **Best F1-Score** | **96.18%** | Throughout presentation |
| **Best Model** | **Linear SVM** | Main result |
| **Total Samples** | 3,761 | Dataset stats |
| **Real RSS News** | 451 | Data collection |
| **Test Samples** | 753 | Requirements check |
| **Training Time (SVM)** | 0.32s | Speed comparison |
| **MCC Score** | 0.9427 | Model quality |
| **Errors** | 29/753 (3.85%) | Error analysis |
| **TF-IDF Features** | 1,000 | Feature engineering |
| **Custom Features** | 14 | Domain knowledge |

---

## ğŸ“Š MODEL COMPARISON TABLE (FOR SLIDES)

```
Model                  CV F1           Test F1    MCC      Time
----------------------------------------------------------------
Linear SVM             0.96 Â± 0.002    96.18%    0.9427   0.32s  â­ BEST
MLP (Deep Learning)    0.96 Â± 0.007    95.54%    0.9330   3.44s
Logistic Regression    0.93 Â± 0.008    93.84%    0.9083   1.60s
Random Forest          0.91 Â± 0.012    91.15%    0.8698   0.10s
```

---

## ğŸ’¬ MUST-KNOW EXPLANATIONS

### "What is Sentiment Analysis?"
> "Bir metnin duygusal tonunu - pozitif, negatif veya nÃ¶tr - otomatik olarak belirleme iÅŸlemi."

### "Why RSS Scraping?"
> "ÃœÃ§ nedeni var: 1) Yasal - herkes iÃ§in aÃ§Ä±k, 2) Temiz veri - baÅŸlÄ±k/tarih dÃ¼zgÃ¼n, 3) GÃ¼ncel - her gÃ¼n yeni haberler."

### "What is TF-IDF?"
> "Term Frequency Ã— Inverse Document Frequency. Nadir ama Ã¶nemli kelimelere yÃ¼ksek skor veriyor. 'the' dÃ¼ÅŸÃ¼k, 'surged' yÃ¼ksek."

### "Why SVM beats MLP?"
> "Finansal sentiment lineer ayrÄ±labilir. 'profit' = pozitif, 'loss' = negatif. KarmaÅŸÄ±k deep learning gereksiz. AyrÄ±ca 10 kat daha hÄ±zlÄ±."

### "What is (2632, 1000)?"
> "2632 cÃ¼mle, her biri 1000 sayÄ± ile temsil ediliyor. Her satÄ±r bir cÃ¼mle, her sÃ¼tun bir Ã¶zellik."

### "What is F1-Score?"
> "Precision ve Recall'Ä±n harmonik ortalamasÄ±. Dengesiz verilerde accuracy'den daha gÃ¼venilir."

### "What is MCC?"
> "Matthews Correlation Coefficient. -1 ile +1 arasÄ±. 0 = rastgele, 1 = mÃ¼kemmel. 0.94 = model ÅŸans deÄŸil, gerÃ§ekten Ã¶ÄŸrenmiÅŸ."

### "What is Cross Validation?"
> "Veriyi 5 parÃ§aya bÃ¶l, 5 kez farklÄ± kombinasyonla test et. Tek testten daha gÃ¼venilir."

### "What is Overfitting?"
> "Model ezberleme yapÄ±yor, yeni veriyi tahmin edemiyor. Learning curves'de train yÃ¼ksek, CV dÃ¼ÅŸÃ¼kse overfitting var. Bizde ikisi yakÄ±n - sorun yok."

---

## ğŸš¨ COMMON QUESTIONS & ANSWERS

### Q: "Neden template kullandÄ±nÄ±z?"
**A:** "451 gerÃ§ek haber yetersiz ve dengesiz (Negative %16). Template'lerle her sÄ±nÄ±fÄ± 550'ye tamamladÄ±k - dengeli veri seti elde ettik."

### Q: "Augmentation nasÄ±l Ã§alÄ±ÅŸÄ±yor?"
**A:** "Synonym replacement: 'profit' â†’ 'earnings', Random swap: kelime yerini deÄŸiÅŸtir, Random deletion: rastgele kelime sil. Anlam aynÄ±, kelimeler farklÄ±."

### Q: "src/ dosyalarÄ± kullanÄ±lÄ±yor mu?"
**A:** "Evet. `sentiment_labeler.py` ve `augmentation.py` create_full_dataset.py'de import ediliyor. `real_scraper.py` ile 451 haber toplandÄ±."

### Q: "%96 Ã§ok yÃ¼ksek deÄŸil mi?"
**A:** "Template ve augmentation kullandÄ±k. Test-train benzer pattern'ler iÃ§eriyor. GerÃ§ek dÃ¼nyada biraz dÃ¼ÅŸÃ¼k olabilir - limitation olarak raporladÄ±k."

### Q: "Neden 1000 feature? Neden 100?"
**A:** "1000 (TF-IDF): En Ã¶nemli kelimeler, fazlasÄ± gÃ¼rÃ¼ltÃ¼ ekler. 100 (Word2Vec): Anlam vektÃ¶rÃ¼, standart boyut. 14 (Custom): Domain bilgisi."

### Q: "Overfitting var mÄ±?"
**A:** "Learning curves'e bakÄ±nca train ve CV yakÄ±n - overfitting yok. L2 regularization ve early stopping kullandÄ±k."

---

## ğŸ¤ SPEAKING TIPS

1. **Slow down** - 15 dakika var, acele etmeyin
2. **Make eye contact** - Hocaya bakÄ±n, ekrana deÄŸil
3. **Use pauses** - Her slayt sonrasÄ± 2-3 saniye duraklayÄ±n
4. **Point to visuals** - "BakÄ±n burada..." diyerek gÃ¶rselleri gÃ¶sterin
5. **Confidence** - "Biz yaptÄ±k, baÅŸardÄ±k" tonunda konuÅŸun

---

## ğŸ”§ EMERGENCY COMMANDS

```bash
# If demo notebook crashes
jupyter notebook --no-browser --port=8888

# If verification fails
python3 reset_and_rebuild.py --yes
python3 create_full_dataset.py
python3 train_and_evaluate.py

# Quick check all files exist
find . -name "*.pkl" -o -name "*_clean.csv" -o -name "*.png"

# Re-run verification
python3 verify_presentation_alignment.py
```

---

## ğŸ“¸ FIGURE LOCATIONS

- `figures/confusion_matrices.png` - Confusion matrices for all models
- `figures/roc_curves.png` - ROC curves with AUC scores
- `figures/learning_curves.png` - Train vs CV scores
- `figures/model_comparison.png` - Bar chart of F1-scores

---

## âœ… FINAL PRE-PRESENTATION CHECK

- [ ] All 4 `.pkl` models exist in `models/`
- [ ] All 3 CSV files in `data/processed/`
- [ ] All figures in `figures/`
- [ ] `verify_presentation_alignment.py` passes âœ…
- [ ] Demo notebook opens without errors
- [ ] Memorized key numbers (96.18%, 3761, 753, 0.32s)
- [ ] Rehearsed explanations for TF-IDF, SVM, F1-Score
- [ ] Prepared for Q&A

---

**Good luck! ğŸ‰ You got this! ğŸ’ª**
